# 《统计机器学习》附加题竞赛—借贷风险预测

给定银行用户信息，建立决策树分类模型，预测银行用户的信用好坏。

## 模型

1. CART决策树：本地0.75，平台0.7652.
2. 随机森林：本地0.78-0.79，平台0.8053.
3. gbdt(梯度提升决策树)：本地0.7984.
4. xgboost+预处理（标准化）：本地到0.806，平台0.8155.
5. catboost+预处理（标准化）：本地0.805，平台0.8126.
6. lightgbm+预处理（标准化）：本地0.8057.
7. SVM+预处理（标准化）：本地0.8018.
8. 模型融合：
   1. 基于权重的投票法（随机森林+xgboost+gbdt）本地0.807，平台0.814（最后发现裸的xgboost最好）
   2. 基于mlp的stacking（xgboost+catboost+lightgbm+svm+随机森林）:本地0.814，平台0.817训练8000*5到8000*1的神经网络

## 特征工程

- 0-1缩放：效果奇差人工分组（分到第五列就放弃了）：没效果
- 标准化：SVM提升巨大，其余模型均有微小提升
- 深度特征合成：效果更差
- 相关性：相关性绝对值比uid更低的特征去除，效果更差

## 调参经验

- 手动调：瞎调

  - 非常不推荐：调种子（本人）

- 贝叶斯搜索：比较快但是比较麻烦

- 网格搜索：最暴力，比较慢但是简单

  - 调哪些参数？

  - 学习率？不建议调的太小，比如本人

  - 将哪些参数分组调？

  - 搜索范围？从大到小调

    ——建议根据不同模型上网搜经验，搜个祖传参数开始调。

## 赛后反思

- 标准化的时候，把train和test一起标准化
- 调参的时候初始范围大一些
- 调参的时候学习率不要太低，特别集成的模型
- 网格搜索的时候，分组调，不要全部一起调模型
- 预测的时候可以不要直接预测0/1而是预测概率值
- 特征工程道阻且长
